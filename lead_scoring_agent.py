# -*- coding: utf-8 -*-
"""lead-scoring-agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yatsj_Uw_l_a6-kPO4ajTEK2pckO_D35
"""

import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
from dataclasses import dataclass
from typing import List, Dict, Optional
import json
from datetime import datetime
import time

@dataclass
class Lead:
    """Data structure for a lead"""
    name: str
    title: str
    company: str
    location: str
    hq_location: str
    email: str = ""
    linkedin: str = ""
    score: int = 0
    scoring_breakdown: Dict = None

class LeadScoringEngine:
    """Engine to calculate propensity-to-buy scores"""

    def __init__(self):
        self.target_keywords = [
            'toxicology', 'safety', 'hepatic', '3d', 'preclinical',
            'drug-induced liver injury', 'dili', 'in vitro', 'organ-on-chip'
        ]
        self.target_titles = [
            'director', 'head', 'vp', 'chief', 'lead', 'principal'
        ]
        self.hub_locations = [
            'boston', 'cambridge', 'bay area', 'san francisco',
            'basel', 'oxford', 'cambridge uk'
        ]

    def calculate_score(self, lead: Lead, additional_data: Dict) -> int:
        """Calculate lead score based on multiple signals"""
        score = 0
        breakdown = {}

        # Role Fit Score (30 points)
        role_score = self._score_role_fit(lead.title)
        score += role_score
        breakdown['role_fit'] = role_score

        # Company Intent Score (20 points)
        company_score = self._score_company_intent(additional_data.get('funding', ''))
        score += company_score
        breakdown['company_intent'] = company_score

        # Technographic Score (15 points)
        tech_score = self._score_technographic(additional_data.get('company_desc', ''))
        score += tech_score
        breakdown['technographic'] = tech_score

        # NAMs/Innovation Score (10 points)
        innovation_score = self._score_innovation(additional_data.get('company_desc', ''))
        score += innovation_score
        breakdown['innovation'] = innovation_score

        # Location Score (10 points)
        location_score = self._score_location(lead.hq_location)
        score += location_score
        breakdown['location'] = location_score

        # Scientific Intent Score (40 points)
        scientific_score = self._score_scientific_intent(additional_data.get('publications', []))
        score += scientific_score
        breakdown['scientific_intent'] = scientific_score

        lead.score = min(score, 100)
        lead.scoring_breakdown = breakdown
        return lead.score

    def _score_role_fit(self, title: str) -> int:
        """Score based on job title relevance"""
        title_lower = title.lower()
        score = 0

        # Check for seniority
        if any(t in title_lower for t in self.target_titles):
            score += 15

        # Check for relevant keywords
        if any(kw in title_lower for kw in self.target_keywords):
            score += 15

        return min(score, 30)

    def _score_company_intent(self, funding_info: str) -> int:
        """Score based on funding status"""
        funding_lower = funding_info.lower()
        if any(term in funding_lower for term in ['series a', 'series b', 'series c']):
            return 20
        elif 'seed' in funding_lower or 'grant' in funding_lower:
            return 10
        return 0

    def _score_technographic(self, company_desc: str) -> int:
        """Score based on technology usage"""
        desc_lower = company_desc.lower()
        tech_keywords = ['in vitro', '3d model', 'organoid', 'organ-on-chip']
        if any(kw in desc_lower for kw in tech_keywords):
            return 15
        return 0

    def _score_innovation(self, company_desc: str) -> int:
        """Score based on NAMs/innovation indicators"""
        desc_lower = company_desc.lower()
        innovation_keywords = ['nam', 'new approach', 'innovative', 'novel']
        if any(kw in desc_lower for kw in innovation_keywords):
            return 10
        return 0

    def _score_location(self, location: str) -> int:
        """Score based on geographic hub"""
        location_lower = location.lower()
        if any(hub in location_lower for hub in self.hub_locations):
            return 10
        return 0

    def _score_scientific_intent(self, publications: List[Dict]) -> int:
        """Score based on recent publications"""
        if not publications:
            return 0

        score = 0
        for pub in publications:
            pub_title = pub.get('title', '').lower()
            pub_year = pub.get('year', 0)

            # Check recency (last 2 years)
            current_year = datetime.now().year
            if current_year - pub_year <= 2:
                # Check for relevant keywords
                if 'dili' in pub_title or 'liver injury' in pub_title:
                    score += 40
                    break
                elif any(kw in pub_title for kw in self.target_keywords):
                    score += 25
                    break

        return min(score, 40)


class PubMedScraper:
    """Scraper for PubMed publications"""

    BASE_URL = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"

    def __init__(self, email: str = "researcher@example.com"):
        self.email = email

    def search_author(self, author_name: str, max_results: int = 5) -> List[Dict]:
        """Search for publications by author"""
        try:
            # Search for papers
            search_url = f"{self.BASE_URL}esearch.fcgi"
            params = {
                'db': 'pubmed',
                'term': f"{author_name}[Author]",
                'retmax': max_results,
                'retmode': 'json',
                'email': self.email
            }

            response = requests.get(search_url, params=params, timeout=10)
            if response.status_code != 200:
                return []

            data = response.json()
            id_list = data.get('esearchresult', {}).get('idlist', [])

            if not id_list:
                return []

            # Fetch paper details
            publications = []
            fetch_url = f"{self.BASE_URL}efetch.fcgi"
            ids = ','.join(id_list[:max_results])

            fetch_params = {
                'db': 'pubmed',
                'id': ids,
                'retmode': 'xml'
            }

            time.sleep(0.5)  # Rate limiting
            fetch_response = requests.get(fetch_url, params=fetch_params, timeout=10)

            if fetch_response.status_code == 200:
                soup = BeautifulSoup(fetch_response.content, 'xml')
                articles = soup.find_all('PubmedArticle')

                for article in articles:
                    title_tag = article.find('ArticleTitle')
                    year_tag = article.find('PubDate').find('Year') if article.find('PubDate') else None

                    publications.append({
                        'title': title_tag.text if title_tag else '',
                        'year': int(year_tag.text) if year_tag else 0
                    })

            return publications

        except Exception as e:
            print(f"Error searching PubMed: {e}")
            return []


class LinkedInDataSimulator:
    """Simulates LinkedIn data (replace with actual API/scraper)"""

    def search_profiles(self, job_titles: List[str], limit: int = 10) -> List[Dict]:
        """Simulate LinkedIn profile search"""
        # In production, use LinkedIn API or Proxycurl
        sample_profiles = [
            {
                'name': 'Dr. Sarah Mitchell',
                'title': 'Director of Toxicology',
                'company': 'BioGenex Therapeutics',
                'location': 'Cambridge, MA',
                'hq_location': 'Cambridge, MA',
                'linkedin': 'https://linkedin.com/in/sarahmitchell',
                'company_desc': 'Biotech focused on 3D in vitro models for drug discovery'
            },
            {
                'name': 'John Chen, PhD',
                'title': 'Head of Preclinical Safety',
                'company': 'NovaPharm Inc',
                'location': 'Remote, CO',
                'hq_location': 'Boston, MA',
                'linkedin': 'https://linkedin.com/in/johnchen',
                'company_desc': 'Series B funded pharmaceutical company'
            },
            {
                'name': 'Dr. Emily Rodriguez',
                'title': 'Principal Scientist - Hepatic Models',
                'company': 'LiverTech Solutions',
                'location': 'Basel, Switzerland',
                'hq_location': 'Basel, Switzerland',
                'linkedin': 'https://linkedin.com/in/emilyrodriguez',
                'company_desc': 'Developing organ-on-chip technology for liver toxicity'
            },
            {
                'name': 'Michael Thompson',
                'title': 'VP of Drug Safety',
                'company': 'Apex Biopharma',
                'location': 'San Francisco, CA',
                'hq_location': 'San Francisco, CA',
                'linkedin': 'https://linkedin.com/in/mthompson',
                'company_desc': 'Series A funded, exploring NAMs for safety assessment'
            },
            {
                'name': 'Dr. Lisa Wang',
                'title': 'Associate Director, DILI Research',
                'company': 'ToxPath Labs',
                'location': 'Oxford, UK',
                'hq_location': 'Oxford, UK',
                'linkedin': 'https://linkedin.com/in/lisawang',
                'company_desc': 'Academic spinout focused on drug-induced liver injury'
            }
        ]

        return sample_profiles[:limit]


class EmailEnricher:
    """Email enrichment (replace with Hunter.io, Clearbit, etc.)"""

    def find_email(self, name: str, company: str) -> str:
        """Simulate email finding"""
        # In production, use Hunter.io API or similar
        first_name = name.split()[0].lower()
        last_name = name.split()[-1].lower()
        company_domain = company.lower().replace(' ', '').replace(',', '')[:10]
        return f"{first_name}.{last_name}@{company_domain}.com"


class LeadGenerationAgent:
    """Main agent orchestrating the lead generation pipeline"""

    def __init__(self):
        self.scoring_engine = LeadScoringEngine()
        self.pubmed_scraper = PubMedScraper()
        self.linkedin_simulator = LinkedInDataSimulator()
        self.email_enricher = EmailEnricher()

    def run_pipeline(self, job_titles: List[str], limit: int = 10) -> pd.DataFrame:
        """Execute the full lead generation pipeline"""
        print("Stage 1: Identifying profiles...")
        profiles = self.linkedin_simulator.search_profiles(job_titles, limit)

        leads = []
        print(f"Stage 2 & 3: Enriching and scoring {len(profiles)} profiles...")

        for idx, profile in enumerate(profiles, 1):
            print(f"Processing {idx}/{len(profiles)}: {profile['name']}")

            # Create lead object
            lead = Lead(
                name=profile['name'],
                title=profile['title'],
                company=profile['company'],
                location=profile['location'],
                hq_location=profile['hq_location'],
                linkedin=profile['linkedin']
            )

            # Enrich with email
            lead.email = self.email_enricher.find_email(lead.name, lead.company)

            # Gather additional data
            publications = self.pubmed_scraper.search_author(lead.name, max_results=3)

            additional_data = {
                'company_desc': profile.get('company_desc', ''),
                'funding': profile.get('company_desc', ''),
                'publications': publications
            }

            # Calculate score
            self.scoring_engine.calculate_score(lead, additional_data)
            leads.append(lead)

            time.sleep(0.3)  # Rate limiting

        # Convert to DataFrame
        df = self._create_dataframe(leads)

        # Sort by score
        df = df.sort_values('Probability', ascending=False).reset_index(drop=True)
        df['Rank'] = range(1, len(df) + 1)

        return df

    def _create_dataframe(self, leads: List[Lead]) -> pd.DataFrame:
        """Convert leads to DataFrame"""
        data = []
        for lead in leads:
            data.append({
                'Rank': 0,  # Will be set after sorting
                'Probability': lead.score,
                'Name': lead.name,
                'Title': lead.title,
                'Company': lead.company,
                'Location': lead.location,
                'HQ': lead.hq_location,
                'Email': lead.email,
                'LinkedIn': lead.linkedin,
                'Scoring_Details': json.dumps(lead.scoring_breakdown)
            })

        return pd.DataFrame(data)


def main():
    """Main execution function"""
    print("="*60)
    print("Lead Generation & Scoring Agent for 3D In-Vitro Models")
    print("="*60)
    print()

    # Initialize agent
    agent = LeadGenerationAgent()

    # Define target job titles
    target_titles = [
        'Director of Toxicology',
        'Head of Preclinical Safety',
        'VP Drug Safety',
        'Principal Scientist'
    ]

    # Run the pipeline
    results_df = agent.run_pipeline(target_titles, limit=5)

    print("\n" + "="*60)
    print("RESULTS - Top Ranked Leads")
    print("="*60)
    print()

    # Display results
    display_columns = ['Rank', 'Probability', 'Name', 'Title', 'Company', 'Location', 'HQ', 'Email']
    print(results_df[display_columns].to_string(index=False))

    # Export to CSV
    output_file = 'lead_generation_results.csv'
    results_df.to_csv(output_file, index=False)
    print(f"\nâœ“ Results exported to {output_file}")

    # Show scoring breakdown for top lead
    print("\n" + "="*60)
    print(f"Scoring Breakdown for Top Lead: {results_df.iloc[0]['Name']}")
    print("="*60)
    breakdown = json.loads(results_df.iloc[0]['Scoring_Details'])
    for category, score in breakdown.items():
        print(f"{category.replace('_', ' ').title()}: {score} points")
    print(f"Total Score: {results_df.iloc[0]['Probability']}/100")

if __name__ == "__main__":
    main()